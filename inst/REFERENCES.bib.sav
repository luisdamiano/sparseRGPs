% Encoding: UTF-8

@Article{neal2003,
  author  = {Radford Neal},
  title   = {Slice Sampling},
  journal = {The Annals of Statistics},
  year    = {2003},
  volume  = {31},
  number  = {3},
  pages   = {705-767},
}

@Article{agarwal2005,
  author  = {Deepak K. Agarwal and Alan Gelfand},
  title   = {Slice sampling for simulation based fitting of spatial data models},
  journal = {Statistics and Computing},
  year    = {2005},
  volume  = {15},
  number  = {1},
  pages   = {61,69},
  month   = jan,
  url     = {https://doi.org/10.1007/s11222-005-4790-z},
}

@InCollection{murray2010a,
  author    = {Iain Murray and Ryan Prescott Adams},
  title     = {Slice sampling covariance hyperparameters of latent {G}aussian models},
  booktitle = {Advances in Neural Information Processing Systems 23},
  publisher = {Curran Associates, Inc.},
  year      = {2010},
  editor    = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
  pages     = {1732--1740},
  url       = {http://papers.nips.cc/paper/4114-slice-sampling-covariance-hyperparameters-of-latent-gaussian-models.pdf},
}

@InProceedings{murray2010b,
  author    = {Iain Murray and Ryan Adams and David MacKay},
  title     = {Elliptical slice sampling},
  booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  year      = {2010},
  editor    = {Yee Whye Teh and Mike Titterington},
  volume    = {9},
  series    = {Proceedings of Machine Learning Research},
  pages     = {541--548},
  address   = {Chia Laguna Resort, Sardinia, Italy},
  month     = {13--15 May},
  publisher = {PMLR},
  abstract  = {Many probabilistic models introduce strong dependencies between variables using a latent multivariate Gaussian distribution or a Gaussian process. We present a new Markov chain Monte Carlo algorithm for performing inference in models with multivariate Gaussian priors. Its key properties are: 1) it has simple, generic code applicable to many models, 2) it has no free parameters, 3) it works well for a variety of Gaussian process based models. These properties make our method ideal for use while model building, removing the need to spend time deriving and tuning updates for more complex algorithms.},
  file      = {murray10a.pdf:http\://proceedings.mlr.press/v9/murray10a/murray10a.pdf:PDF},
  url       = {http://proceedings.mlr.press/v9/murray10a.html},
}

@Article{duane1987,
  author  = {Simon Duane and Anthony D. Kennedy and Brian J. Pendleton and Duncan Roweth},
  title   = {Hybrid monte carlo},
  journal = {Physics letters B},
  year    = {1987},
  volume  = {195},
  number  = {2},
  pages   = {216-222},
}

@Article{candela2005,
  author  = {Joaquin Qui{\~n}onero-Candela and Carl Edward Rasmussen},
  title   = {A Unifying View of Sparse Approximate {G}aussian Process Regression},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  pages   = {1939},
}

@Article{finley2009,
  author  = {Andrew O. Finley and Huiyan Sang and Sudipto Banerjee and Alan E. Gelfand},
  title   = {Improving the performance of predictive process modeling for large datasets},
  journal = {Computational Statistics \& Data Analysis},
  year    = {2009},
  volume  = {53},
  number  = {8},
  pages   = {2873-2884},
  month   = jun,
  doi     = {https://doi.org/10.1016/j.csda.2008.09.008},
}

@InCollection{snelson2006,
  author    = {Edward Snelson and Zoubin Ghahramani},
  title     = {Sparse {G}aussian Processes using Pseudo-inputs},
  booktitle = {Advances in Neural Information Processing Systems 18},
  publisher = {MIT Press},
  year      = {2006},
  editor    = {Y. Weiss and B. Sch\"{o}lkopf and J. C. Platt},
  pages     = {1257--1264},
  url       = {http://papers.nips.cc/paper/2857-sparse-gaussian-processes-using-pseudo-inputs.pdf},
}

@InProceedings{vanhatalo2007,
  author    = {Jarno Vanhatalo and Aki Vehtari},
  title     = {Sparse Log Gaussian Processes via MCMC for Spatial Epidemiology},
  booktitle = {Gaussian processes in practice},
  year      = {2007},
  pages     = {73-89},
}

@InProceedings{titsias2009,
  author    = {Michalis Titsias},
  title     = {Variational learning of inducing variables in sparse {G}aussian processes},
  booktitle = {Artificial Intelligence and Statistics},
  year      = {2009},
  pages     = {567-574},
}

@Article{banerjee2008,
  author  = {Sudipto Banerjee and Alan E. Gelfand and Andrew O. Finley and Huiyan Sang},
  title   = {Gaussian predictive process models for large spatial data sets},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year    = {2008},
  volume  = {70},
  number  = {4},
  pages   = {825-848},
}

@Article{hensman2013,
  author  = {James Hensman and Nicolo Fusi and Niel D. Lawrence},
  title   = {{G}aussian processes for big data},
  journal = {arXiv preprint arXiv:1309.6835},
  year    = {2013},
}

@Article{vanhatalo2010,
  author  = {Jarno Vanhatalo and Ville Pietil{\"a}inen and Aki Vehtari},
  title   = {Approximate inference for disease mapping with sparse Gaussian processes},
  journal = {Statistics in medicine},
  year    = {2010},
  volume  = {29},
  number  = {15},
  pages   = {1580-1607},
}

@InProceedings{seeger2003,
  author    = {Matthias Seeger and Christopher Williams and Neil Lawrence},
  title     = {Fast forward selection to speed up sparse {G}aussian process regression},
  booktitle = {Artificial Intelligence and Statistics},
  year      = {2003},
}

@Article{hensman2015,
  author  = {James Hensman and Alexander Matthews and Zoubin Ghahramani},
  title   = {Scalable variational {G}aussian process classification},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
}

@Article{eidsvik2012,
  author  = {Jo Eidsvik and Andrew O. Finley and Sudipto Banerjee and Havard Rue},
  title   = {Approximate Bayesian inference for large spatial datasets using predictive process models},
  journal = {Computational statistics and data analysis},
  year    = {2012},
  volume  = {56},
  pages   = {1362-1380},
}

@InProceedings{cao2013,
  author    = {Yanshuai Cao and Marcus A Brubaker and David J Fleet and Aaron Hertzmann},
  title     = {Efficient optimization for sparse {G}aussian process regression},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2013},
  pages     = {1097-1105},
}

@Book{rasmussen2006,
  title     = {Gaussian Processes for Machine Learning},
  publisher = {MIT Press},
  year      = {2006},
  author    = {Carl Edward Rasmussen and Christopher K.I. Williams},
  editor    = {Thomas Dietterich},
}

@Article{evett2000,
  author  = {IW Evett and G Jackson and JA Lambert and S Mc{C}rossan},
  title   = {The impact of the principles of evidence interpretation on the structure and content of statements},
  journal = {Science \& Justice},
  year    = {2000},
  volume  = {40},
  number  = {4},
  pages   = {233-239},
  month   = oct,
  url     = {https://doi.org/10.1016/S1355-0306(00)71993-9},
}

@Article{grove1980,
  author  = {Daniel M. Grove},
  title   = {The interpretation of forensic evidence using a likelihood ratio},
  journal = {Biometrika},
  year    = {1980},
  volume  = {67},
  number  = {1},
  pages   = {243-246},
  month   = apr,
}

@Article{hepler2012,
  author  = {Amanda B. Hepler and Christopher P. Saunders and Linda J. Davis and Jo{A}nn Buscaglia},
  title   = {Score-based likelihood ratios for handwriting evidence},
  journal = {Forensic Science International},
  year    = {2012},
  volume  = {219},
  pages   = {129-140},
}

@Article{lindley1977,
  author  = {Dennis V. Lindley},
  title   = {A problem in forensic science},
  journal = {{B}iometrika},
  year    = {1977},
  volume  = {64},
  number  = {2},
  pages   = {207-213},
  month   = aug,
}

@Article{marin2013,
  author   = {Marin, Jean-Michel and Pillai, Natesh S. and Robert, Christian P. and Rousseau, Judith},
  title    = {Relevant statistics for Bayesian model choice},
  journal  = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year     = {2013},
  volume   = {76},
  number   = {5},
  pages    = {833-859},
  abstract = {Summary The choice of the summary statistics that are used in Bayesian inference and in particular in approximate Bayesian computation algorithms has bearings on the validation of the resulting inference. Those statistics are nonetheless customarily used in approximate Bayesian computation algorithms without consistency checks. We derive necessary and sufficient conditions on summary statistics for the corresponding Bayes factor to be convergent, namely to select the true model asymptotically. Those conditions, which amount to the expectations of the summary statistics differing asymptotically under the two models, are quite natural and can be exploited in approximate Bayesian computation settings to infer whether or not a choice of summary statistics is appropriate, via a Monte Carlo validation.},
  doi      = {10.1111/rssb.12056},
  eprint   = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12056},
  keywords = {Ancillarity, Approximate Bayesian computation, Asymptotics, Bayes factor, Bayesian model choice, Gaussianity, Likelihood-free methods, Sufficiency},
  url      = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12056},
}

@Article{marquis2016,
  author  = {Raymond Marquis and Alex Biedermann and Liv Cadola and Christophe Champod and Line Gueissaz and Genevi{\`e}ve Massonet and Williams David Mazzella and Franco Taroni and Tacha Hicks},
  title   = {Discussion on how to implement a verbal scale in a forensic laboratory: Benefits, pitfalls and suggestions to avoid misunderstandings},
  journal = {Science and Justice},
  year    = {2016},
  volume  = {56},
  number  = {5},
  pages   = {364-370},
  month   = sep,
  url     = {https://doi.org/10.1016/j.scijus.2016.05.009},
}

@Article{nordgaard2012,
  author  = {Anders Nordgaard and Birgitta Rasmusson},
  title   = {The likelihood ratio as value of evidence - more than a question of numbers},
  journal = {Law, Probability and Risk},
  year    = {2012},
  volume  = {11},
  number  = {4},
  pages   = {303-315},
  month   = jul,
  doi     = {10.1093/lpr/mgs019},
}

@Article{robert2011,
  author  = {Christian P. Robert and Jean-Marie Cornuet and Jean-Michel Marin and Natesh S. Pillai},
  title   = {Lack of confidence in approximate {B}ayesian computation of model choice},
  journal = {Proceedings of the National Academy of Sciences},
  year    = {2011},
  volume  = {108},
  number  = {37},
  pages   = {15112-15117},
  month   = sep,
  url     = {https://doi.org/10.1073/pnas.1102900108},
}

@Article{taroni1998,
  author  = {F. Taroni and C. Champod and P. Margot},
  title   = {Forerunners of Bayesianism in Early Forensic Science},
  journal = {Jurimetrics},
  year    = {1998},
  volume  = {38},
  number  = {2},
  url     = {https://www.jstor.org/stable/29762536},
}

@Article{morrison2018,
  author  = {Geoffrey Stewart Morrison and Ewald Enzinger},
  title   = {Score based procedures for the calculation of forensic likelihood ratios - Scores should take account of both similarity and typicality},
  journal = {Science and Justice},
  year    = {2018},
  volume  = {58},
  pages   = {47-58},
}

@Article{stern2017,
  author  = {Hal S. Stern},
  title   = {Statistical Issues in Forensic Science},
  journal = {Annual Review of Statistics and Its Applications},
  year    = {2017},
  volume  = {4},
  pages   = {225-244},
}

@InProceedings{lobato2016,
  author    = {Daniel Hernandez-Lobato and Jose Miguel Hernandez-Lobato},
  title     = {Scalable {G}aussian Process Classification via Expectation Propagation},
  booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  year      = {2016},
  editor    = {Arthur Gretton and Christian C. Robert},
  volume    = {51},
  series    = {Proceedings of Machine Learning Research},
  pages     = {168--176},
  address   = {Cadiz, Spain},
  month     = {09--11 May},
  publisher = {PMLR},
  abstract  = {Variational methods have been recently considered for scaling the training process of Gaussian process classifiers to large datasets. As an alternative, we describe here how to train these classifiers efficiently using expectation propagation (EP). The proposed EP method allows to train Gaussian process classifiers on very large datasets, with millions of instances, that were out of the reach of previous implementations of EP. More precisely, it can be used for (i) training in a distributed fashion where the data instances are sent to different nodes in which the required computations are carried out, and for (ii) maximizing an estimate of the marginal likelihood using a stochastic approximation of the gradient. Several experiments involving large datasets show that the method described is competitive with the variational approach.},
  file      = {hernandez-lobato16.pdf:http\://proceedings.mlr.press/v51/hernandez-lobato16.pdf:PDF},
  url       = {http://proceedings.mlr.press/v51/hernandez-lobato16.html},
}

@InProceedings{williams2001,
  author    = {Christopher KI Williams and Matthias Seeger},
  title     = {Advances in neural information processing systems},
  booktitle = {Using the Nystr{\"o}m method to speed up kernel machines},
  year      = {2001},
  pages     = {682-688},
}

@Article{datta2016,
  author  = {Abhirup Datta and Sudipto Banerjee and Andrew O. Finley and Alan E. Gelfand},
  title   = {Hierarchical nearest-neighbor {G}aussian process models for large geostatistical datasets},
  journal = {Journal of the American Statistical Association},
  year    = {2016},
  volume  = {111},
  number  = {514},
  pages   = {800--812},
}

@InProceedings{smola2001,
  author    = {Alex J Smola and Peter L Bartlett},
  title     = {Sparse greedy {G}aussian process regression},
  booktitle = {Advances in neural information processing systems},
  year      = {2001},
  pages     = {619-625},
}

@Article{csato2002,
  author  = {Lehel Csat{\'o} and Manfred Opper},
  title   = {Sparse on-line Gaussian processes},
  journal = {Neural computation},
  year    = {2002},
  volume  = {14},
  number  = {3},
  pages   = {641-668},
}

@Misc{uci,
  author = {Dheeru Dua and Casey Graff},
  title  = {{UCI} Machine Learning Repository},
  year   = {2017},
  owner  = {University of California, Irvine, School of Information and Computer Sciences },
  url    = {http://archive.ics.uci.edu/ml},
}

@Misc{zeiler2012,
  author = {Matthew D. Zeiler},
  title  = {{ADADELTA:} An Adaptive Learning Rate Method},
  year   = {2012},
  url    = {https://arxiv.org/abs/1212.5701},
}

@Article{jones1998,
  author  = {Donald R. Jones and Matthias Schonlau and William J. Welch},
  title   = {Efficient Global Optimization of Expensive Black-Box Functions},
  journal = {Journal of Global Optimization},
  year    = {1998},
  volume  = {13},
  number  = {4},
  pages   = {455-492},
}

@Article{shahriari2016,
  author  = {B. {Shahriari} and K. {Swersky} and Z. {Wang} and R. P. {Adams} and N. {de Freitas}},
  title   = {Taking the Human Out of hte Loop: A Review of Bayesian Optimization},
  journal = {Proceedings of the IEEE},
  year    = {2016},
  volume  = {104},
  number  = {1},
  pages   = {148-175},
}

@Article{jones2001,
  author  = {Donald R. Jones},
  title   = {A Taxonomy of Global Optimization Methods Based on Response Surfaces},
  journal = {Journal of Global Optimization},
  year    = {2001},
  volume  = {21},
  number  = {4},
  pages   = {345--383},
}

@Article{nickish2008,
  author  = {Hannes Nickish and Carl Edward Rasmussen},
  title   = {Approximations for Binary Gaussian Process Classification},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  pages   = {2035-2078},
}

@Manual{spatstat.data,
  title  = {spatstat.data: Datasets for 'spatstat'},
  author = {Adrian Baddeley and Rolf Turner and Ege Rubak},
  year   = {2018},
  note   = {R package version 1.4-0},
  url    = {https://CRAN.R-project.org/package=spatstat.data},
}

@InProceedings{ginsbourger2009,
  author    = {Ginsbourger, David and Le Riche, Rodolphe},
  title     = {Towards GP-based optimization with finite time horizon},
  booktitle = {{mODa 9} - Advances in Model-Oriented Design and Analysis},
  year      = {2009},
  editor    = {Alessandra Giovagnoli and Anthony C. Atkinson and Bernard Torsney and Caterina May},
  series    = {Contributions to Statistics},
  pages     = {89-96},
}

@Article{moller1998,
  author  = {M{\o}ller, Jesper and Syversveen, Anne Randi and Waagepetersen, Rasmus Plenge},
  title   = {Log gaussian cox processes},
  journal = {Scandinavian journal of statistics},
  year    = {1998},
  volume  = {25},
  number  = {3},
  pages   = {451-482},
  doi     = {10.1111/1467-9469.00115},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9469.00115},
}

@Article{vanhatalo2013,
  author  = {Jarno Vanhatalo and Jaakko Riihim{\"a}ki and Jouni Hartikainen and Pasi Jyl{\"a}nki and Ville Tolvanen and Aki Vehtari},
  title   = {{GP}stuff: {B}ayesian modeling with {G}aussian processes},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  number  = {1},
  pages   = {1175-1179},
}

@Article{rasmussen2010,
  author  = {Carl Edward Rasmussen and Hannes Nickish},
  title   = {{G}aussian Processes for Machine Learning (GPML) Toolbox},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  pages   = {3011-3015},
  month   = nov,
}

@InCollection{bauer2016,
  author    = {Bauer, Matthias and van der Wilk, Mark and Rasmussen, Carl Edward},
  title     = {Understanding Probabilistic Sparse {G}aussian Process Approximations},
  booktitle = {Advances in Neural Information Processing Systems 29},
  publisher = {Curran Associates, Inc.},
  year      = {2016},
  editor    = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
  pages     = {1533--1541},
  url       = {http://papers.nips.cc/paper/6477-understanding-probabilistic-sparse-gaussian-process-approximations.pdf},
}

@Article{blei2017,
  author    = {David M. Blei and Alp Kucukelbir and Jon D. McAuliffe},
  title     = {Variational Inference: A Review for Statisticians},
  journal   = {Journal of the American Statistical Association},
  year      = {2017},
  volume    = {112},
  number    = {518},
  pages     = {859-877},
  doi       = {10.1080/01621459.2017.1285773},
  eprint    = {https://doi.org/10.1080/01621459.2017.1285773},
  publisher = {Taylor \& Francis},
  url       = { 
        https://doi.org/10.1080/01621459.2017.1285773
    
},
}

@TechReport{titsias2009b,
  author      = {Michalis Titsias},
  title       = {Variational Model Selection for Sparse {G}aussian Process Regression},
  institution = {University of Manchester},
  year        = {2009},
}

@PhdThesis{gonzalez2008,
  author = {Roberto L{\'o}pez Gonz{\'a}lez},
  title  = {Neural Networks for Variational Problems in Engineering},
  school = {Technical University of Catalonia},
  year   = {2008},
}

@Article{,
}

@Article{tufekci2014,
  author    = {T{\"u}fekci, P{\i}nar},
  title     = {Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods},
  journal   = {International Journal of Electrical Power \& Energy Systems},
  year      = {2014},
  volume    = {60},
  pages     = {126--140},
  publisher = {Elsevier},
}

@InProceedings{kaya2012,
  author    = {Kaya, Heysem and T{\"u}fekci, Pmar and G{\"u}rgen, Fikret S},
  title     = {Local and global learning methods for predicting power of a combined gas \& steam turbine},
  booktitle = {Proceedings of the international conference on emerging trends in computer and electronics engineering {ICETCEE}},
  year      = {2012},
  pages     = {13--18},
}

@InProceedings{guzman2008,
  author        = {Naish-Guzman, Andrew and Holden, Sean},
  title         = {The generalized FITC approximation},
  booktitle     = {Advances in neural information processing systems},
  year          = {2008},
  pages         = {1057--1064},
  __markedentry = {[Nate:]},
}

@Article{jordan1999,
  author        = {Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  title         = {An introduction to variational methods for graphical models},
  journal       = {Machine learning},
  year          = {1999},
  volume        = {37},
  number        = {2},
  pages         = {183--233},
  __markedentry = {[Nate:]},
  publisher     = {Springer},
}

@Article{Adams2009,
  author        = {Adams, Ryan Prescott and Murray, Iain and MacKay, David JC},
  title         = {Nonparametric Bayesian density modeling with Gaussian processes},
  journal       = {arXiv preprint arXiv:0912.4896},
  year          = {2009},
  __markedentry = {[Nate:6]},
}

@Article{garton2020oat,
  author  = {Nathaniel Garton and Jarad Niemi and Alicia Carriquiry},
  title   = {Knot Selection in Sparse Gaussian Processes},
  journal = {arXiv preprint arXiv:2002.09538},
  year    = {2020},
}

@Comment{jabref-meta: databaseType:bibtex;}
